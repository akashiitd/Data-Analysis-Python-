{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The digits recognition dataset\\nUp until now, you have been performing binary classification, since the target variable had two possible outcomes. Hugo, however, got to perform multi-class classification in the videos, where the target variable could take on three possible outcomes. Why does he get to have all the fun?! In the following exercises, you'll be working with the MNIST digits recognition dataset, which has 10 classes, the digits 0 through 9! A reduced version of the MNIST dataset is one of scikit-learn's included datasets, and that is the one we will use in this exercise.\\n\\nEach sample in this scikit-learn dataset is an 8x8 image representing a handwritten digit. Each pixel is represented by an integer in the range 0 to 16, indicating varying levels of black. Recall that scikit-learn's built-in datasets are of type Bunch, which are dictionary-like objects. Helpfully for the MNIST dataset, scikit-learn provides an 'images' key in addition to the 'data' and 'target' keys that you have seen with the Iris data. Because it is a 2D array of the images corresponding to each sample, this 'images' key is useful for visualizing the images, as you'll see in this exercise (for more on plotting 2D arrays, see Chapter 2 of DataCamp's course on Data Visualization with Python). On the other hand, the 'data' key contains the feature array - that is, the images as a flattened array of 64 pixels.\\n\\nNotice that you can access the keys of these Bunch objects in two different ways: By using the . notation, as in digits.images, or the [] notation, as in digits['images'].\\n\\nFor more on the MNIST data, check out this exercise in Part 1 of DataCamp's Importing Data in Python course. There, the full version of the MNIST dataset is used, in which the images are 28x28. It is a famous dataset in machine learning and computer vision, and frequently used as a benchmark to evaluate the performance of a new model.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The digits recognition dataset\n",
    "Up until now, you have been performing binary classification, since the target variable had two possible outcomes. Hugo, however, got to perform multi-class classification in the videos, where the target variable could take on three possible outcomes. Why does he get to have all the fun?! In the following exercises, you'll be working with the MNIST digits recognition dataset, which has 10 classes, the digits 0 through 9! A reduced version of the MNIST dataset is one of scikit-learn's included datasets, and that is the one we will use in this exercise.\n",
    "\n",
    "Each sample in this scikit-learn dataset is an 8x8 image representing a handwritten digit. Each pixel is represented by an integer in the range 0 to 16, indicating varying levels of black. Recall that scikit-learn's built-in datasets are of type Bunch, which are dictionary-like objects. Helpfully for the MNIST dataset, scikit-learn provides an 'images' key in addition to the 'data' and 'target' keys that you have seen with the Iris data. Because it is a 2D array of the images corresponding to each sample, this 'images' key is useful for visualizing the images, as you'll see in this exercise (for more on plotting 2D arrays, see Chapter 2 of DataCamp's course on Data Visualization with Python). On the other hand, the 'data' key contains the feature array - that is, the images as a flattened array of 64 pixels.\n",
    "\n",
    "Notice that you can access the keys of these Bunch objects in two different ways: By using the . notation, as in digits.images, or the [] notation, as in digits['images'].\n",
    "\n",
    "For more on the MNIST data, check out this exercise in Part 1 of DataCamp's Importing Data in Python course. There, the full version of the MNIST dataset is used, in which the images are 28x28. It is a famous dataset in machine learning and computer vision, and frequently used as a benchmark to evaluate the performance of a new model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "from scipy.stats import nanmean\n",
    "\n",
    "def fill_missing_values(X):\n",
    "    \"\"\" imputing missing values before building a learner \"\"\"\n",
    "    mean=nanmean(X,axis=0)\n",
    "    for rows in xrange(len(X)):\n",
    "        for cols in xrange(len(X[rows])):\n",
    "            if np.isnan(X[rows][cols]):\n",
    "                X[rows][cols]=mean[cols]\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "#!/usr/bin/env python\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "subjects={\"English\":0,\"Physics\":1,\"Chemistry\":2, \"ComputerScience\":3,\"Biology\":4,\\\n",
    "        \"PhysicalEducation\":5, \"Economics\":6,\"Accountancy\":7,\"BusinessStudies\":8,\\\n",
    "        \"Mathematics\":9,\"serial\":10}\n",
    "\n",
    "def get_x(data):\n",
    "    x=[np.nan]*9;\n",
    "    for key in data.keys():\n",
    "        if subjects[key]<=8:\n",
    "            x[subjects[key]]=data[key]\n",
    "    return x\n",
    "\n",
    "def get_y(data):\n",
    "    for key in data.keys():\n",
    "        if subjects[key]==9:    #Mathematics\n",
    "            y=data[key]\n",
    "    return y\n",
    "\n",
    "def load_training_data(filename):\n",
    "    X=[];Y=[]\n",
    "    f=open(filename,\"r\")\n",
    "    nline=int(f.readline())\n",
    "    for i in xrange(nline):\n",
    "        data=json.loads(f.readline())\n",
    "        X.append(get_x(data))\n",
    "        Y.append(get_y(data))\n",
    "    return (X,Y)\n",
    "\n",
    "def load_test_data(xfilename,yfilename):\n",
    "    X=[];Y=[]\n",
    "    fx=open(xfilename,\"r\")\n",
    "    fy=open(yfilename,\"r\")\n",
    "    nline=int(fx.readline())\n",
    "    for i in xrange(nline):\n",
    "        data=json.loads(fx.readline())\n",
    "        X.append(get_x(data))\n",
    "        Y.append(int(fy.readline()))\n",
    "    return (X,Y)\n",
    "\n",
    "def load_input():\n",
    "    X=[]\n",
    "    n=int(raw_input())\n",
    "    for i in xrange(n):\n",
    "        data=json.loads(raw_input())\n",
    "        X.append(get_x(data))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree\n",
    "#!/usr/bin/env python\n",
    "from datasets import load_training_data,load_test_data\n",
    "from preprocessing import fill_missing_values\n",
    "\n",
    "\"\"\" get training data \"\"\"\n",
    "Xtr,Ytr=load_training_data(\"data/training.json\")\n",
    "Xtr=fill_missing_values(Xtr)\n",
    "\n",
    "\"\"\" get test data \"\"\"\n",
    "Xte,Yte=load_test_data(\"data/sample-test.in.json\",\"data/sample-test.out.json\")\n",
    "Xte=fill_missing_values(Xte)\n",
    "\n",
    "\"\"\"training\"\"\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "learner = DecisionTreeClassifier(max_depth=7,random_state=0).fit(Xtr, Ytr)\n",
    "\n",
    "\"\"\"predicting\"\"\"\n",
    "print learner.score(Xtr,Ytr)\n",
    "print learner.score(Xte,Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
